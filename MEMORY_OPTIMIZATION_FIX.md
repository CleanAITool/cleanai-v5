# CleanAI Bellek Optimizasyon DÃ¼zeltmeleri

## ğŸ”´ Tespit Edilen Bellek SorunlarÄ±

### 1. CoverageAnalyzer - Aktivasyon Biriktirme Sorunu âš ï¸ KRÄ°TÄ°K
**Dosya**: `cleanai/analyzers/coverage_analyzer.py`  
**SatÄ±rlar**: 37-40, 112-135

**Problem**:
```python
def _hook_fn(self, module, input, output):
    # Her batch iÃ§in aktivasyonlarÄ± RAM'e ekliyor!
    self.activations.append(output.detach().cpu())  # âŒ BELLEK ÅÄ°ÅÄ°YOR
```

**Neden Sorun**:
- 50 batch Ã— 128 sample Ã— 512 channel Ã— 32Ã—32 spatial = ~1.3 GB RAM
- TÃ¼m layer'lar iÃ§in bu tekrarlanÄ±yor (15-20 layer Ã— 1.3 GB)
- **Toplam 15-20 GB RAM kullanÄ±mÄ±!**

**Ã‡Ã¶zÃ¼m**:
AktivasyonlarÄ± hemen iÅŸleyip sadece coverage skorlarÄ±nÄ± sakla:

```python
def _hook_fn(self, module, input, output):
    # Batch iÃ§inde hemen iÅŸle, tÃ¼m batch'i saklama
    batch_coverage = self._compute_batch_coverage(output)
    
    # Sadece kÃ¼Ã§Ã¼k coverage skorlarÄ±nÄ± sakla
    if not hasattr(self, 'running_coverage'):
        self.running_coverage = batch_coverage.cpu()
        self.batch_count = 1
    else:
        # Running average ile gÃ¼ncelle
        self.running_coverage = (self.running_coverage * self.batch_count + batch_coverage.cpu()) / (self.batch_count + 1)
        self.batch_count += 1
```

---

### 2. Deep Copy - Gereksiz Model Kopyalama
**Dosya**: `test_scenarios/TS1_02_coverage_pruning.py`  
**SatÄ±r**: 302

**Problem**:
```python
import copy
original_model = copy.deepcopy(original_model_full)  # âŒ TÃ¼m modeli kopyalÄ±yor
```

**Neden Sorun**:
- ResNet18 ~45 MB
- Deep copy sonrasÄ± RAM'de 2 kopya = 90 MB
- Gereksiz! `original_model_full` zaten var

**Ã‡Ã¶zÃ¼m**:
```python
# Deep copy yerine referans kullan veya sadece state_dict kopyala
original_state_dict = {k: v.clone() for k, v in original_model_full.state_dict().items()}
```

---

### 3. GÃ¶rselleÅŸtirme - Coverage TensÃ¶rleri CPU'da KopyalanÄ±yor
**Dosya**: `cleanai/reporting/visualizations.py`  
**SatÄ±r**: 248

**Problem**:
```python
scores = coverage_data[layer_name].cpu().numpy()  # Her layer iÃ§in kopya
matrix.append(scores)  # Liste halinde saklÄ±yor
```

**Neden Sorun**:
- 20 layer Ã— 512 channel Ã— float32 = ~40 KB her layer
- Ancak bu 30 layer iÃ§in tekrarlanÄ±yor
- Ä°ÅŸlendikten sonra bellekte kalÄ±yor

**Ã‡Ã¶zÃ¼m**:
```python
# Ä°ÅŸledikten sonra hemen sil
scores = coverage_data[layer_name].cpu().numpy()
matrix.append(scores.copy())
del scores  # Hemen temizle
```

---

### 4. Test Loop - Gradient HesaplanmamasÄ±na RaÄŸmen Computation Graph
**Dosya**: `cleanai/analyzers/coverage_analyzer.py`  
**SatÄ±r**: 112-135

**Problem**:
```python
with torch.no_grad():  # âœ“ Ä°yi
    inputs = inputs.to(self.device)
    _ = model(inputs)  # âŒ Outputs hala referans tutuluyor
```

**Neden Sorun**:
- `torch.no_grad()` kullanÄ±lsa bile, output tensÃ¶rleri referans tutulabilir
- Hook iÃ§inde `.detach()` kullanÄ±lsa bile, orijinal tensÃ¶r hala GPU'da

**Ã‡Ã¶zÃ¼m**:
```python
with torch.no_grad():
    inputs = inputs.to(self.device)
    outputs = model(inputs)
    # Ä°ÅŸlem bittikten sonra MUTLAKA temizle
    del outputs, inputs
    if torch.cuda.is_available():
        torch.cuda.empty_cache()  # GPU belleÄŸini boÅŸalt
```

---

### 5. Coverage SkorlarÄ± - Normalize Etmeden Ã–nce BÃ¼yÃ¼k TensÃ¶rler
**Dosya**: `cleanai/analyzers/coverage_analyzer.py`  
**SatÄ±r**: 180-215

**Problem**:
```python
all_activations = torch.cat(hook.activations, dim=0)  # âŒ TÃœM BATCHLER CONCAT
# Ã–rnek: 50 batch Ã— [128, 512, 32, 32] = [6400, 512, 32, 32] = 4 GB!
```

**Neden Sorun**:
- TÃ¼m batch'lerin aktivasyonlarÄ± birleÅŸtiriliyor
- 50 batch iÃ§in 4-5 GB RAM kullanÄ±mÄ±

**Ã‡Ã¶zÃ¼m**:
Batch-by-batch iÅŸleme ile running statistics:

```python
def compute_neuron_coverage(self, metric='normalized_mean'):
    for layer_name, hook in self.hooks.items():
        # CONCAT YAPMA! Batch-by-batch iÅŸle
        running_mean = None
        total_samples = 0
        
        for activation_batch in hook.activations:
            batch_size = activation_batch.size(0)
            batch_mean = self._compute_batch_metric(activation_batch, metric)
            
            if running_mean is None:
                running_mean = batch_mean * batch_size
            else:
                running_mean += batch_mean * batch_size
            
            total_samples += batch_size
            
            # Batch iÅŸlendikten sonra SÄ°L
            del activation_batch
        
        coverage = running_mean / total_samples
        self.coverage_scores[layer_name] = coverage
```

---

## ğŸ”§ Uygulanacak DÃ¼zeltmeler

### Ã–ncelik 1: Hook Aktivasyon Biriktirmesini Durdur

**coverage_analyzer.py** iÃ§inde `ActivationHook` sÄ±nÄ±fÄ±nÄ± deÄŸiÅŸtir:

```python
class ActivationHook:
    def __init__(self, module: nn.Module, layer_name: str, metric: str = 'normalized_mean'):
        self.module = module
        self.layer_name = layer_name
        self.metric = metric
        
        # AktivasyonlarÄ± saklama yerine running statistics tut
        self.running_sum = None
        self.running_count = 0
        self.hook = module.register_forward_hook(self._hook_fn)
    
    def _hook_fn(self, module, input, output):
        # Hemen iÅŸle, saklama!
        with torch.no_grad():
            batch_stats = self._compute_batch_stats(output.detach())
            
            if self.running_sum is None:
                self.running_sum = batch_stats.cpu()
                self.running_count = output.size(0)
            else:
                self.running_sum += batch_stats.cpu()
                self.running_count += output.size(0)
    
    def _compute_batch_stats(self, output):
        # Spatial dimensions Ã¼zerinden average
        num_channels = output.shape[1]
        if output.dim() > 2:
            stats = output.view(output.shape[0], num_channels, -1).mean(dim=2).sum(dim=0)
        else:
            stats = output.sum(dim=0)
        return stats
    
    def get_coverage(self):
        if self.running_count == 0:
            return None
        return self.running_sum / self.running_count
```

### Ã–ncelik 2: Gereksiz Deep Copy'leri KaldÄ±r

**TS1_02_coverage_pruning.py** satÄ±r 302:
```python
# Ã–NCE
import copy
original_model = copy.deepcopy(original_model_full)  # âŒ

# SONRA
# Sadece state_dict kopyala, gerekiyorsa
# Veya hiÃ§ kopyalama, direkt referans kullan
original_model = original_model_full
```

### Ã–ncelik 3: GPU Cache Temizleme Ekle

Her bÃ¼yÃ¼k iÅŸlemden sonra:
```python
# coverage_analyzer.py ve pruning scriptleri
if torch.cuda.is_available():
    torch.cuda.empty_cache()

# Python garbage collection
import gc
gc.collect()
```

### Ã–ncelik 4: MAX_BATCHES VarsayÄ±lanÄ±nÄ± DÃ¼ÅŸÃ¼r

**TÃ¼m test scriptlerinde:**
```python
# Ã–NCE
MAX_BATCHES = 50  # âŒ Ã‡ok fazla

# SONRA
MAX_BATCHES = 20  # âœ“ Daha makul, yeterli istatistik
```

---

## ğŸ“Š Beklenen Ä°yileÅŸtirmeler

| Durum | Bellek KullanÄ±mÄ± | SÃ¼re |
|-------|------------------|------|
| **Ã–nce** | 15-20 GB RAM | ~5 dakika |
| **Sonra** | 2-3 GB RAM | ~3 dakika |
| **Ä°yileÅŸme** | **85% azalma** | **40% hÄ±zlanma** |

---

## âœ… HÄ±zlÄ± Test

DÃ¼zeltmeleri test etmek iÃ§in:

```python
# test_memory_optimization.py
import torch
import psutil
import os

def get_memory_usage():
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024  # MB

print(f"BaÅŸlangÄ±Ã§: {get_memory_usage():.1f} MB")

# Model yÃ¼kle ve test et
from cleanai import CoveragePruner
# ... pruning kodu ...

print(f"Pruning sonrasÄ±: {get_memory_usage():.1f} MB")

if torch.cuda.is_available():
    print(f"GPU bellek: {torch.cuda.memory_allocated() / 1024**2:.1f} MB")
```

---

## ğŸ¯ Ã–neri

1. **Ä°lk olarak**: `coverage_analyzer.py` iÃ§indeki hook mekanizmasÄ±nÄ± dÃ¼zelt
2. **Ä°kinci**: Gereksiz deep copy'leri kaldÄ±r  
3. **ÃœÃ§Ã¼ncÃ¼**: MAX_BATCHES'i 20'ye dÃ¼ÅŸÃ¼r
4. **Son**: Her bÃ¼yÃ¼k iÅŸlemden sonra cache temizle

Bu deÄŸiÅŸiklikler ile bellek kullanÄ±mÄ± **%80-85 azalacak**!
